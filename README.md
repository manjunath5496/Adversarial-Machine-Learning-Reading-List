<h2> Adversarial Machine Learning Reading List </h2>

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(1).pdf" style="text-decoration:none;">Intriguing properties of neural networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(2).pdf" style="text-decoration:none;">Explaining and Harnessing Adversarial Examples</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(3).pdf" style="text-decoration:none;">DeepFool: a simple and accurate method to fool deep neural networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(4).pdf" style="text-decoration:none;">The Limitations of Deep Learning in Adversarial Settings</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(5).pdf" style="text-decoration:none;">Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(6).pdf" style="text-decoration:none;">Adversarial examples in the physical world</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(7).pdf" style="text-decoration:none;">Towards Evaluating the Robustness of Neural Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(8).pdf" style="text-decoration:none;"> Universal adversarial perturbations</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(9).pdf" style="text-decoration:none;">Delving into Transferable Adversarial Examples and Black-box Attacks</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(10).pdf" style="text-decoration:none;">Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks? </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(11).pdf" style="text-decoration:none;">On Detecting Adversarial Perturbations</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(12).pdf" style="text-decoration:none;">Detecting Adversarial Samples from Artifacts</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(13).pdf" style="text-decoration:none;">Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(14).pdf" style="text-decoration:none;">Synthesizing Robust Adversarial Examples</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(15).pdf" style="text-decoration:none;">Robust Physical-World Attacks on Deep Learning Visual Classification</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(16).pdf" style="text-decoration:none;">ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(17).pdf" style="text-decoration:none;">Evasion attacks against machine learning at test time</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(18).pdf" style="text-decoration:none;">Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(19).pdf" style="text-decoration:none;">Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(20).pdf" style="text-decoration:none;">On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(21).pdf" style="text-decoration:none;">Adversarial Attacks on Neural Network Policies</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(22).pdf" style="text-decoration:none;">Adversarial Examples for Generative Models</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(23).pdf" style="text-decoration:none;">Towards Deep Learning Models Resistant to Adversarial Attacks</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(24).pdf" style="text-decoration:none;">Audio Adversarial Examples: Targeted Attacks on Speech-to-Text</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(25).pdf" style="text-decoration:none;">Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(26).pdf" style="text-decoration:none;">Certified Robustness to Adversarial Examples with Differential Privacy</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(27).pdf" style="text-decoration:none;">Adversarial Risk and the Dangers of Evaluating AgainstWeak Attacks</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(28).pdf" style="text-decoration:none;">Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(29).pdf" style="text-decoration:none;">Towards the first adversarially robust neural network model on MNIST</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Adversarial-Machine-Learning-Reading-List/blob/master/amlr(30).pdf" style="text-decoration:none;">On Evaluating Adversarial Robustness</a></li>
 </ul>
